import logging
import random
import re

import emoji
import vk_api
from vk_api.bot_longpoll import VkBotEventType, VkBotLongPoll

from interfaces.algorithm import (
    load_abuse_word,
    load_insult_word,
    load_toxic_emojis,
)
from interfaces.utils.algorithm_functions import load_model

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
insult_words_path = "data/extend_insults.txt"
abuse_words_path = "data/abuse_words.txt"
toxic_emojis_path = "data/toxic_emoji.txt"


class VKBase:
    def __init__(self, token, group_id):
        self.token = token
        self.group_id = int(group_id)
        self.vk_session = vk_api.VkApi(token=token)
        self.longpoll = VkBotLongPoll(self.vk_session, group_id)
        self.vk = self.vk_session.get_api()


class VKBot(VKBase):
    def __init__(self, token, group_id):
        super().__init__(token, group_id)
        self.group_id = int(group_id)
        self.model = None
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Ç–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.insult_words = load_insult_word()
        self.abuse_words = load_abuse_word()
        self.toxic_emojis = load_toxic_emojis()

    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
        self.load_model()

        for event in self.longpoll.listen():
            if event.type == VkBotEventType.MESSAGE_NEW:
                self.handle_message(event)

    def handle_message(self, event):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        try:
            user_id = event.message.from_id
            conversation_message_id = event.message.conversation_message_id
            peer_id = event.message.peer_id
            text = event.message.text.lower()

            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user_id}: {text}")

            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
            if text == "–ø—Ä–∏–≤–µ—Ç":
                self.send_message(peer_id, "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?")
            elif text == "–ø–æ–∫–∞":
                self.delete_message(
                    peer_id, conversation_message_id=conversation_message_id
                )
                self.send_message(
                    peer_id, "–ò–∑–≤–∏–Ω–∏, –Ω–∞–º –ø—Ä–∏—à–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ç–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ :("
                )
            elif "–∫–∞–∫ –¥–µ–ª–∞" in text:
                self.send_message(peer_id, "–£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ! –ê —É –≤–∞—Å?")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
            result = self.predict_toxicity(text)
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: {result}")
            if result == "is_toxic":
                self.delete_message(
                    peer_id, conversation_message_id=conversation_message_id
                )
                self.send_message(peer_id, self.get_warning_message())
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

    def get_warning_message(self):
        return """
üéØ *–û–π-–æ–π-–æ–π!* üéØ
–í–∞—à —Å–ª–æ–≤–∞—Ä–Ω—ã–π –∑–∞–ø–∞—Å –Ω–µ–º–Ω–æ–≥–æ "–æ–±–æ–≥–∞—Ç–∏–ª—Å—è" –Ω–µ —Ç–µ–º–∏ —Å–ª–æ–≤–∞–º–∏! üíé
                
üé™ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞:
üé≠ –¶–µ–Ω–∑—É—Ä–Ω—ã–π —Ä–µ–∂–∏–º
üé® –ö—Ä–∞—Å–∏–≤—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
üòä –í–µ–∂–ª–∏–≤—ã–π —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è
                
–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ! üåà
"""

    def send_message(self, peer_id, message, keyboard=None):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
        try:
            params = {
                "peer_id": peer_id,
                "message": message,
                "random_id": random.randint(1, 1000000),
            }

            if keyboard:
                params["keyboard"] = keyboard

            self.vk.messages.send(**params)
        except Exception as e:
            logger.warning(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {message}.\n–û—à–∏–±–∫–∞: {e}"
            )

    def delete_message(
        self, peer_id, delete_for_all=True, conversation_message_id=None
    ):
        """–£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            params = {
                "cmids": conversation_message_id,
                "delete_for_all": delete_for_all,
                "peer_id": peer_id,
                "group_id": self.group_id,
            }

            self.vk.messages.delete(**params)
            logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ {conversation_message_id} —É–¥–∞–ª–µ–Ω–æ")
        except Exception as e:
            logger.warning(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {conversation_message_id}. –û—à–∏–±–∫–∞: {e}"
            )

    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å"""
        try:
            self.model = load_model()
            logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            self.model = None

    def predict_toxicity(self, text):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        if not self.model:
            return "is_normal"

        try:
            clean_text = re.sub(r"[^\w\s]", " ", text.lower())
            words = clean_text.split()

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞, –∞ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—ã–π —Ä–∞–∑
            insult_count = sum(
                1 for word in words if word in self.insult_words
            )

            abuse_count = sum(1 for word in words if word in self.abuse_words)

            found_emojis = [char for char in text if char in emoji.EMOJI_DATA]

            emoji_count = sum(
                1 for char in found_emojis if char in self.toxic_emojis
            )

            features = [[insult_count, emoji_count, abuse_count]]

            prediction = self.model.predict(features)[0]
            probabilities = self.model.predict_proba(features)[0]
            result = "is_toxic" if prediction else "is_normal"

            # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
            confidence = probabilities[prediction]

            # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            logger.info(
                f"–ü—Ä–∏–∑–Ω–∞–∫–∏: –º–∞—Ç—ã={insult_count}, —ç–º–æ–¥–∑–∏={emoji_count}, –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è={abuse_count}"
            )
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}, –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}")
            logger.info(
                f"–í—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ={probabilities[0]:.3f}, —Ç–æ–∫—Å–∏—á–Ω–æ–µ={probabilities[1]:.3f}"
            )
            return result
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            return "is_normal"

